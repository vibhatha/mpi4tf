# -*- coding: utf-8 -*-
"""tensorflow_mnist_gradient_tape.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vtXQnFKliVldGm6uj3qhZGn5ize_Ecy9
"""

# !pip install tensorflow-gpu==2.0.0b1

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals
import os
import tensorflow as tf

import cProfile


tf.executing_eagerly()

(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()

dataset = tf.data.Dataset.from_tensor_slices(
    (tf.cast(mnist_images[..., tf.newaxis] / 255, tf.float32),
     tf.cast(mnist_labels, tf.int64)))
dataset = dataset.shuffle(1000).batch(32)

# Build the model
mnist_model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, [3, 3], activation='relu',
                           input_shape=(None, None, 1)),
    tf.keras.layers.Conv2D(16, [3, 3], activation='relu'),
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(10)
])

with tf.device('/gpu:0'):
    layer1 = tf.keras.Sequential([
        tf.keras.layers.Conv2D(16, [3, 3], activation='relu',
                               input_shape=(None, None, 1))
    ])

with tf.device('/gpu:1'):
    layer2 = tf.keras.Sequential([
        tf.keras.layers.Conv2D(16, [3, 3], activation='relu')
    ])

with tf.device('/gpu:2'):
    layer3 = tf.keras.Sequential([
        tf.keras.layers.GlobalAveragePooling2D()
    ])

with tf.device('/gpu:3'):
    layer4 = tf.keras.Sequential([
        tf.keras.layers.Dense(10)
    ])

dist_mnist_model = tf.keras.Sequential([
    layer1,
    layer2,
    layer3,
    layer4
])

for images, labels in dataset.take(1):
    print("Logits: ", mnist_model(images[0:1]).numpy())

for images, labels in dataset.take(1):
    print("Logits: ", dist_mnist_model(images[0:1]).numpy())

optimizer = tf.keras.optimizers.Adam()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

loss_history = []

dist_loss_history = []


def train_step(images, labels):
    with tf.GradientTape() as tape:
        logits = mnist_model(images, training=True)

        # Add asserts to check the shape of the output.
        tf.debugging.assert_equal(logits.shape, (32, 10))

        loss_value = loss_object(labels, logits)

    loss_history.append(loss_value.numpy().mean())
    grads = tape.gradient(loss_value, mnist_model.trainable_variables)
    optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))


def dist_train_step(images, labels):
    with tf.GradientTape() as tape:
        logits = dist_mnist_model(images, training=True)

        # Add asserts to check the shape of the output.
        tf.debugging.assert_equal(logits.shape, (32, 10))

        loss_value = loss_object(labels, logits)

    dist_loss_history.append(loss_value.numpy().mean())
    grads = tape.gradient(loss_value, dist_mnist_model.trainable_variables)
    optimizer.apply_gradients(zip(grads, dist_mnist_model.trainable_variables))


def train(epochs):
    for epoch in range(epochs):
        for (batch, (images, labels)) in enumerate(dataset):
            train_step(images, labels)
        print('Epoch {} finished'.format(epoch))


def dist_train(epochs):
    for epoch in range(epochs):
        for (batch, (images, labels)) in enumerate(dataset):
            dist_train_step(images, labels)
        print('Epoch {} finished'.format(epoch))


import time
#
# t1 = time.time()
# with tf.device('/cpu:0'):
#     train(epochs=3)
# print("CPU TIME : {}".format(time.time() - t1))

t1 = time.time()
dist_train(epochs=3)
print("GPU Time : {}".format(time.time() - t1))

# import matplotlib.pyplot as plt
#
# plt.plot(loss_history)
# plt.xlabel('Batch #')
# plt.ylabel('Loss [entropy]')
#
# import matplotlib.pyplot as plt
#
# plt.plot(dist_loss_history)
# plt.xlabel('Batch #')
# plt.ylabel('Dist Loss [entropy]')

